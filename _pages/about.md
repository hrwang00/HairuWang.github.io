---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>
# üëã About Me

Hi, everyone! I earned my bachelor‚Äôs degree at Harbin Institute of Technology in 2023. In the same year, I joined the School of Computer Science at USTC for my master's degree. Currently, I am a third-year M.S. candidate jointly supervised by Prof. [Prof. Xike Xie](http://staff.ustc.edu.cn/~xkxie/) and [Prof. S. Kevin Zhou](https://scholar.google.com/citations?user=8eNm2GMAAAAJ&hl=en). Please don‚Äôt hesitate to reach out for any discussion. You can contact me via Email: hrwang00@mail dot ustc dot edu dot cn. I am always open to engaging in intriguing research endeavors! üòä

My research interests include NNs' memory, Large Language Models, LLM efficiency, and RAG.


# üî• News
- 2025.06 One papers was accepted by Information Fusion.
- 2025.05 One papers was accepted by ICML 2025.
- 2024.09 Two papers were accepted by EMNLP 2024 Main.

# üìù Publications 

[**Efficient Generative Model Training via Embedded Representation Warmup**](https://arxiv.org/abs/2504.10188)

**Deyuan Liu**, Peng Sun, Xufeng Li, Tao Lin

*ICCV 2025 Under Review*

[**SAIL: Accelerating Model Training via Structured Initialization**](https://openreview.net/forum?id=MSlF3GvUXI&referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3DICLR.cc%2F2025%2FConference%2FAuthors%23your-submissions))

**Deyuan Liu**, Peng Sun, Xufeng Li, Tao Lin

[**How Stable is the Next Token? A Geometric View of LLM Prediction Stability**](#)

**Deyuan Liu**, Zhanyue Qin, Yantai Yang, Zhiying Tu, Dianhui Chu, Dianbo Sui

*NeurIPS 2025 Under Review*

[**Maximizing Intermediate Checkpoint Value in LLM Pretraining with Bayesian Optimization**](https://arxiv.org/abs/2403.19390)

**Deyuan Liu**, Zecheng Wang, Bingning Wang, Weipeng Chen, Chunshan Li, Zhiying Tu, Dianhui Chu, Bo Li, Dianbo Sui

*ICML 2025*


[**Pruning via Merging: Compressing LLMs via Manifold Alignment Based Layer Merging**](https://arxiv.org/abs/2406.16330)

**Deyuan Liu**, Zhanyue Qin, Hairu Wang, Zhao Yang, Zecheng Wang, Fangying Rong, Qingbin Liu, Yanchao Hao, Xi Chen, Cunhang Fan, Zhao Lv, Zhiying Tu, Dianhui Chu, Bo Li, Dianbo Sui

*EMNLP 2024 Main, TPAMI Under Review*


[**Towards Enhanced LLM Pretraining: Dynamic Checkpoint Merging via Generation Quality**](#)

Zecheng Wang, **Deyuan Liu**, Chunshan Li, Dianhui Chu, Weipeng Chen, Bingning Wang, Dianbo Sui

*Information Fusion*


# üìñ Education
- *2023.09 - 2026.06*, Master in Computer Science and Technology, University of Science and Technology of China (USTC).
- *2019.09 - 2023.06*, Bachelor in Software Engineering, Harbin Institute of Technology (HIT).
